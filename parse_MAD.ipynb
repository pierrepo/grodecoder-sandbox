{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve an HTML page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://mad.ibcp.fr/explore\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        Response\n",
      "\u001b[0;31mString form:\u001b[0m <Response [200]>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/grodecoder-env/lib/python3.11/site-packages/requests/models.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "The :class:`Response <Response>` object, which contains a\n",
      "server's response to an HTTP request."
     ]
    }
   ],
   "source": [
    "# look at the status of the response, if it worked or not\n",
    "# 200: it works // 404: this page doen't exist // 500: server encountered an error\n",
    "?response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!doctype html><html lang=\"en\"><head><meta charset=\"utf-8\"/><link rel=\"icon\" href=\"/favicon.ico\"/><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/><meta name=\"theme-color\" content=\"#000000\"/><meta name=\"description\" content=\"MArtini Database\"/><link rel=\"apple-touch-icon\" href=\"/apple-touch-icon.png\"/><link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&display=swap\"/><link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\"/><script src=\"/all.min.js\" defer=\"defer\" async></script><title>MAD - MArtini Database - Database for coarse grained biomolecules</title><meta name=\"keywords\" content=\"MAD, MArtini Database, Martinize, CGMartini, INSANE, Coarse grained\"><meta name=\"title\" content=\"MArtini Database\"><meta name=\"description\" content=\"MArtini Database references high quality coarse grained models and let you upload yours.\"><meta property=\"og:type\" content=\"website\"><meta property=\"og:url\" content=\"https://metatags.io/\"><meta property=\"og:title\" content=\"https://mad.ibcp.fr/\"><meta property=\"og:description\" content=\"MArtini Database references high quality coarse grained models and let you upload yours.\"><meta property=\"og:image\" content=\"https://mad.ibcp.fr/assets/logo.png\"><meta property=\"twitter:card\" content=\"summary_large_image\"><meta property=\"twitter:url\" content=\"https://mad.ibcp.fr/\"><meta property=\"twitter:title\" content=\"MArtini Database\"><meta property=\"twitter:description\" content=\"MArtini Database references high quality coarse grained models and let you upload yours.\"><meta property=\"twitter:image\" content=\"https://mad.ibcp.fr/assets/logo.png\"><link href=\"/static/css/main.0ec1c1b5.chunk.css\" rel=\"stylesheet\"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id=\"root\"></div><script>!function(e){function t(t){for(var n,i,l=t[0],a=t[1],f=t[2],p=0,s=[];p<l.length;p++)i=l[p],Object.prototype.hasOwnProperty.call(o,i)&&o[i]&&s.push(o[i][0]),o[i]=0;for(n in a)Object.prototype.hasOwnProperty.call(a,n)&&(e[n]=a[n]);for(c&&c(t);s.length;)s.shift()();return u.push.apply(u,f||[]),r()}function r(){for(var e,t=0;t<u.length;t++){for(var r=u[t],n=!0,l=1;l<r.length;l++){var a=r[l];0!==o[a]&&(n=!1)}n&&(u.splice(t--,1),e=i(i.s=r[0]))}return e}var n={},o={1:0},u=[];function i(t){if(n[t])return n[t].exports;var r=n[t]={i:t,l:!1,exports:{}};return e[t].call(r.exports,r,r.exports,i),r.l=!0,r.exports}i.m=e,i.c=n,i.d=function(e,t,r){i.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},i.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},i.t=function(e,t){if(1&t&&(e=i(e)),8&t)return e;if(4&t&&\"object\"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(i.r(r),Object.defineProperty(r,\"default\",{enumerable:!0,value:e}),2&t&&\"string\"!=typeof e)for(var n in e)i.d(r,n,function(t){return e[t]}.bind(null,n));return r},i.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return i.d(t,\"a\",t),t},i.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},i.p=\"/\";var l=this[\"webpackJsonpmartinize-db-client\"]=this[\"webpackJsonpmartinize-db-client\"]||[],a=l.push.bind(l);l.push=t,l=l.slice();for(var f=0;f<l.length;f++)t(l[f]);var c=a;r()}([])</script><script src=\"/static/js/2.5810a25f.chunk.js\"></script><script src=\"/static/js/main.9700cb35.chunk.js\"></script></body></html>'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve the page's content\n",
    "response.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the page's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert this HTML code into something more readable\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <link href=\"/favicon.ico\" rel=\"icon\"/>\n",
      "  <meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/>\n",
      "  <meta content=\"#000000\" name=\"theme-color\"/>\n",
      "  <meta content=\"MArtini Database\" name=\"description\"/>\n",
      "  <link href=\"/apple-touch-icon.png\" rel=\"apple-touch-icon\"/>\n",
      "  <link href=\"https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&amp;display=swap\" rel=\"stylesheet\"/>\n",
      "  <link href=\"https://fonts.googleapis.com/icon?family=Material+Icons\" rel=\"stylesheet\"/>\n",
      "  <script async=\"\" defer=\"defer\" src=\"/all.min.js\">\n",
      "  </script>\n",
      "  <title>\n",
      "   MAD - MArtini Database - Database for coarse grained biomolecules\n",
      "  </title>\n",
      "  <meta content=\"MAD, MArtini Database, Martinize, CGMartini, INSANE, Coarse grained\" name=\"keywords\"/>\n",
      "  <meta content=\"MArtini Database\" name=\"title\"/>\n",
      "  <meta content=\"MArtini Database references high quality coarse grained models and let you upload yours.\" name=\"description\"/>\n",
      "  <meta content=\"website\" property=\"og:type\"/>\n",
      "  <meta content=\"https://metatags.io/\" property=\"og:url\"/>\n",
      "  <meta content=\"https://mad.ibcp.fr/\" property=\"og:title\"/>\n",
      "  <meta content=\"MArtini Database references high quality coarse grained models and let you upload yours.\" property=\"og:description\"/>\n",
      "  <meta content=\"https://mad.ibcp.fr/assets/logo.png\" property=\"og:image\"/>\n",
      "  <meta content=\"summary_large_image\" property=\"twitter:card\"/>\n",
      "  <meta content=\"https://mad.ibcp.fr/\" property=\"twitter:url\"/>\n",
      "  <meta content=\"MArtini Database\" property=\"twitter:title\"/>\n",
      "  <meta content=\"MArtini Database references high quality coarse grained models and let you upload yours.\" property=\"twitter:description\"/>\n",
      "  <meta content=\"https://mad.ibcp.fr/assets/logo.png\" property=\"twitter:image\"/>\n",
      "  <link href=\"/static/css/main.0ec1c1b5.chunk.css\" rel=\"stylesheet\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <noscript>\n",
      "   You need to enable JavaScript to run this app.\n",
      "  </noscript>\n",
      "  <div id=\"root\">\n",
      "  </div>\n",
      "  <script>\n",
      "   !function(e){function t(t){for(var n,i,l=t[0],a=t[1],f=t[2],p=0,s=[];p<l.length;p++)i=l[p],Object.prototype.hasOwnProperty.call(o,i)&&o[i]&&s.push(o[i][0]),o[i]=0;for(n in a)Object.prototype.hasOwnProperty.call(a,n)&&(e[n]=a[n]);for(c&&c(t);s.length;)s.shift()();return u.push.apply(u,f||[]),r()}function r(){for(var e,t=0;t<u.length;t++){for(var r=u[t],n=!0,l=1;l<r.length;l++){var a=r[l];0!==o[a]&&(n=!1)}n&&(u.splice(t--,1),e=i(i.s=r[0]))}return e}var n={},o={1:0},u=[];function i(t){if(n[t])return n[t].exports;var r=n[t]={i:t,l:!1,exports:{}};return e[t].call(r.exports,r,r.exports,i),r.l=!0,r.exports}i.m=e,i.c=n,i.d=function(e,t,r){i.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},i.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},i.t=function(e,t){if(1&t&&(e=i(e)),8&t)return e;if(4&t&&\"object\"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(i.r(r),Object.defineProperty(r,\"default\",{enumerable:!0,value:e}),2&t&&\"string\"!=typeof e)for(var n in e)i.d(r,n,function(t){return e[t]}.bind(null,n));return r},i.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return i.d(t,\"a\",t),t},i.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},i.p=\"/\";var l=this[\"webpackJsonpmartinize-db-client\"]=this[\"webpackJsonpmartinize-db-client\"]||[],a=l.push.bind(l);l.push=t,l=l.slice();for(var f=0;f<l.length;f++)t(l[f]);var c=a;r()}([])\n",
      "  </script>\n",
      "  <script src=\"/static/js/2.5810a25f.chunk.js\">\n",
      "  </script>\n",
      "  <script src=\"/static/js/main.9700cb35.chunk.js\">\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display HTML code with indentation\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCII_SPACES, DEFAULT_BUILDER_FEATURES, DEFAULT_INTERESTING_STRING_TYPES, EMPTY_ELEMENT_EVENT, END_ELEMENT_EVENT, NO_PARSER_SPECIFIED_WARNING, ROOT_TAG_NAME, START_ELEMENT_EVENT, STRING_ELEMENT_EVENT, append, attrs, builder, can_be_empty_element, cdata_list_attributes, childGenerator, children, clear, contains_replacement_characters, contents, css, currentTag, current_data, declared_html_encoding, decode, decode_contents, decompose, decomposed, default, descendants, element_classes, encode, encode_contents, endData, extend, extract, fetchNextSiblings, fetchParents, fetchPrevious, fetchPreviousSiblings, find, findAll, findAllNext, findAllPrevious, findChild, findChildren, findNext, findNextSibling, findNextSiblings, findParent, findParents, findPrevious, findPreviousSibling, findPreviousSiblings, find_all, find_all_next, find_all_previous, find_next, find_next_sibling, find_next_siblings, find_parent, find_parents, find_previous, find_previous_sibling, find_previous_siblings, format_string, formatter_for_name, get, getText, get_attribute_list, get_text, handle_data, handle_endtag, handle_starttag, has_attr, has_key, hidden, index, insert, insert_after, insert_before, interesting_string_types, isSelfClosing, is_empty_element, is_xml, known_xml, markup, name, namespace, new_string, new_tag, next, nextGenerator, nextSibling, nextSiblingGenerator, next_element, next_elements, next_sibling, next_siblings, object_was_parsed, open_tag_counter, original_encoding, parent, parentGenerator, parents, parse_only, parserClass, parser_class, popTag, prefix, preserve_whitespace_tag_stack, preserve_whitespace_tags, prettify, previous, previousGenerator, previousSibling, previousSiblingGenerator, previous_element, previous_elements, previous_sibling, previous_siblings, pushTag, recursiveChildGenerator, renderContents, replaceWith, replaceWithChildren, replace_with, replace_with_children, reset, select, select_one, self_and_descendants, setup, smooth, string, string_container, string_container_stack, strings, stripped_strings, tagStack, text, unwrap, wrap\n"
     ]
    }
   ],
   "source": [
    "methods = \", \".join([method for method in dir(soup)\n",
    "                     if not method.startswith(\"_\")])\n",
    "print(methods)  # All the methods that can be use on BeautifulSoup object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'il y en a beaucoup. On va se concentrer sur les méthodes ```.find()``` et ```.find_all()``` qui permettent de récupérer des éléments HTML en fonction de leur nom, de leur classe, de leur id, et la méthode ```.get_text()``` qui permet de récupérer le texte contenu dans un élément HTML.\n",
    "\n",
    "1. ***Méthode ```.find_all(name, attrs, recursive, string, limit, **kwargs)```*** permet de rechercher et de récupérer tous les éléments HTML correspondant à certains critères. Elle renvoie une liste d'objets BeautifulSoup contenant tous les éléments trouvés. <br>\n",
    "Paramètres : </br>\n",
    "- ```name``` (facultatif) : Le nom de la balise HTML à rechercher. (Exemple : ```name=\"title\"```)\n",
    "- ```attrs``` (facultatif) : Un dictionnaire contenant des attributs et leurs valeurs pour filtrer les éléments. (Exemple : ```attrs={\"class\": \"my-class\", \"id\": \"my-id\"}```)\n",
    "- ```recursive``` (facultatif) : Un booléen qui indique si la recherche doit être effectuée dans les sous-éléments. (Exemple : ```recursive=False```)\n",
    "- ```string``` (facultatif) : Un filtre sur le contenu textuel des éléments. (Exemple : ```string=\"my-text\"```)\n",
    "- ```limit``` (facultatif) : Un entier qui indique le nombre maximum d'éléments à renvoyer. (Exemple : ```limit=5```)\n",
    "- ```**kwargs``` (facultatif) : Des filtres supplémentaires sur les attributs. (Exemple : ```class_=\"my-class\", id=\"my-id\"```)\n",
    "\n",
    "2. ***Méthode ```.find(name, attrs, recursive, string, **kwargs)```*** permet de rechercher et de récupérer le premier élément HTML correspondant à certains critères, tels que le nom de la balise, la classe, l'ID, ou d'autres attributs. Elle renvoie un objet BeautifulSoup correspondant au premier élément trouvé.\n",
    "\n",
    "3. ***Méthode ```.get_text(separator, strip, types)```*** permet de récupérer le texte contenu dans un élément HTML.<br>\n",
    "Paramètres :</br>\n",
    "- ```separator``` (facultatif) : Le séparateur à utiliser entre les éléments. (Exemple : ```separator=\" \"```)\n",
    "- ```strip``` (facultatif) : Un booléen qui indique si les espaces doivent être supprimés. (Exemple : ```strip=True```)\n",
    "- ```types``` (facultatif) : Une liste de types d'éléments à inclure. (Exemple : ```types=[\"p\", \"a\"]```)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saw that the previous method can't read JS script from URL, so we must try an other method\n",
    "https://www.zenrows.com/blog/playwright-scraping#what-is-playwright  \n",
    "https://oxylabs.io/blog/playwright-web-scraping  \n",
    "https://medium.com/thedevproject/how-to-scrape-javascript-heavy-sites-like-a-pro-with-python-1ecf6f829538  \n",
    "  \n",
    "Use the package async_playwright to load JavaScript content from a website (with the entire script), by run it into a browser. Where BeautifulSoup only parse HTML and XML code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio  # https://docs.python.org/3/library/asyncio.html\n",
    "from playwright.async_api import async_playwright  # imports the asynchronous version of Playwright, a library used to automate browsers.\n",
    "from bs4 import BeautifulSoup  # parse HTML and XML documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def: indicates that this function will be executed asynchronously\n",
    "async def scrape_with_playwright(url): \n",
    "    async with async_playwright() as p:  # launch Playwright asynchronously. This ensures that resources are properly freed once the operation is complete.\n",
    "        # await: indicates that this operation is asynchronous and that the function will wait for the browser to be launched before continuing.\n",
    "        browser = await p.chromium.launch(headless=True)  # Start browser. Can change 'chromium' by \"firefox\" or \"webkit\".\n",
    "        page = await browser.new_page()  # Opens a new page in the launched browser\n",
    "        \n",
    "        # Load the page at the specified URL. This operation is asynchronous and will wait until the page is completely loaded.\n",
    "        await page.goto(url)\n",
    "        \n",
    "        # Wait for JS content to load before continuing\n",
    "        await page.wait_for_selector('tbody')\n",
    "        \n",
    "        # Retrieves the all the HTML content from the page after JavaScript execution\n",
    "        html_content = await page.content()\n",
    "        \n",
    "        # Close the browser. This operation is asynchronous and will wait until the browser is completely closed.\n",
    "        await browser.close()\n",
    "        return html_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(url):\n",
    "    html_content = await scrape_with_playwright(url)\n",
    "    \n",
    "    # Analyze the HTML content \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://mad.ibcp.fr/explore'\n",
    "HTML_content = await main(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td class=\"MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall\"><a class=\"jss38\" href=\"/molecule/THC?version=1112458835848635523\"> tetrahydrocannabinol </a></td>\n",
      " tetrahydrocannabinol  \n",
      "\n",
      "<td class=\"MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall\"><a class=\"jss38\" href=\"/molecule/THC?version=1112458835848635523\">THC</a></td>\n",
      "THC \n",
      "\n",
      "<td class=\"MuiTableCell-root MuiTableCell-body MuiTableCell-alignRight MuiTableCell-sizeSmall\"><div class=\"\">Small molecule</div></td>\n",
      "Small molecule \n",
      "\n",
      "<td class=\"MuiTableCell-root MuiTableCell-body MuiTableCell-alignRight MuiTableCell-sizeSmall\"><div class=\"\">2024-03-14 22:37</div></td>\n",
      "2024-03-14 22:37 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look how the first line is organize \n",
    "rows = HTML_content.find(\"tbody\").find_all(\"tr\")\n",
    "for row in rows:\n",
    "    cells = row.find_all(\"td\")\n",
    "    for cell in cells:\n",
    "        print(cell)\n",
    "        print(cell.get_text(), '\\n')\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect everything in a function, to automate the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_with_playwright(url: str) -> str: \n",
    "    \"\"\"Scrapes the HTML content of a webpage using Playwright.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        url: str\n",
    "            The URL of the webpage to be scraped.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        str\n",
    "            The HTML content of the specified webpage.\n",
    "    \"\"\"\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        \n",
    "        await page.goto(url)\n",
    "        await page.wait_for_selector('tbody')\n",
    "        html_content = await page.content()\n",
    "        await browser.close()\n",
    "        \n",
    "        return html_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(url: str) -> BeautifulSoup:\n",
    "    \"\"\"Fetches and parses the HTML content of a webpage using Playwright and BeautifulSoup.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        url: str\n",
    "            The URL of the webpage to be scraped.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        BeautifulSoup\n",
    "            A BeautifulSoup object representing the parsed HTML content of the webpage.\n",
    "    \"\"\"\n",
    "    html_content = await scrape_with_playwright(url)\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_max(soup: BeautifulSoup) -> bool:\n",
    "    \"\"\"Check if the current page is the last page of results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        soup: BeautifulSoup)\n",
    "            A BeautifulSoup object containing the parsed HTML\n",
    "            of the current page.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        bool\n",
    "            True if the current page is the last page of results, False otherwise.\n",
    "    \"\"\"\n",
    "    rows = soup.find(\"tfoot\").find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        cell = row.find(\"p\")\n",
    "        current_page = cell.get_text()\n",
    "        tmp = current_page.split()\n",
    "        tot_elmt_now = int(tmp[0].split('-')[1])\n",
    "        tot_elmt = int(tmp[-1])           \n",
    "        return tot_elmt_now == tot_elmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_MAD_one(page: int, recordings: list[dict[str, str]]) -> list[dict[str, str]]:\n",
    "    \"\"\"Parse data from the MAD website for a single page.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        page: int\n",
    "            The page number to parse.\n",
    "        recordings: list[dict[str, str]]\n",
    "            A list of dictionaries containing previously parsed recordings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        list[dict[str, str]]\n",
    "            The updated list of recordings after parsing the specified page.\n",
    "    \"\"\"\n",
    "    url = f\"https://mad.ibcp.fr/explore?page={page}\"\n",
    "    loop = asyncio.get_event_loop()\n",
    "    soup = loop.run_until_complete(main(url))\n",
    "    \n",
    "    rows = soup.find(\"tbody\").find_all(\"tr\")\n",
    "    base_url = \"https://mad.ibcp.fr\"\n",
    "    col_names = [col.get_text() for col in soup.select(\"th\")]\n",
    "    col_names.append(\"Lien\")\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_all(\"td\")\n",
    "        link = row.find(\"a\")\n",
    "        link_href = base_url + link.get(\"href\")\n",
    "        recording = {name: value.get_text(strip=True)\n",
    "                        for name, value in zip(col_names, cells)\n",
    "                        if name != \"Created at\"}\n",
    "        recording[\"Lien\"] = link_href\n",
    "        recordings.append(recording)\n",
    "        \n",
    "    if not is_max(soup): parse_MAD_one(page+1, recordings)\n",
    "    return recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_MAD_loop() -> pd.core.frame.DataFrame:\n",
    "    \"\"\"Parse data from the MAD website for multiple pages using a loop.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pd.core.frame.DataFrame\n",
    "            DataFrame containing the parsed data from the MAD website.\n",
    "    \"\"\"\n",
    "    recordings = []\n",
    "    data = parse_MAD_one(1, recordings)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('lipid_MAD.csv', sep=';', index=False, header=True, columns=df.columns.tolist())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Alias</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lien</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tetrahydrocannabinol</td>\n",
       "      <td>THC</td>\n",
       "      <td>Small molecule</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/THC?version=11124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N-arachidonyl-ethanolamide</td>\n",
       "      <td>AEA</td>\n",
       "      <td>Small molecule</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/AEA?version=11124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C60 fullerene model</td>\n",
       "      <td>F16</td>\n",
       "      <td>Synthetic nanoparticles</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/F16?version=66864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F216 fullerene model</td>\n",
       "      <td>F216</td>\n",
       "      <td>Synthetic nanoparticles</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/F216?version=6686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F576 fullerene model</td>\n",
       "      <td>F576</td>\n",
       "      <td>Synthetic nanoparticles</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/F576?version=6686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>beta-Lactose</td>\n",
       "      <td>LAC</td>\n",
       "      <td>Sugars</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/LAC?version=82073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Sucrose</td>\n",
       "      <td>SUCR</td>\n",
       "      <td>Sugars</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/SUCR?version=8207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Trehalose</td>\n",
       "      <td>TREH</td>\n",
       "      <td>Sugars</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/TREH?version=8207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Monosialodihexosylganglioside</td>\n",
       "      <td>DPG3</td>\n",
       "      <td>Lipids</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/DPG3?version=8389...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Globotriaosylceramide</td>\n",
       "      <td>Gb3</td>\n",
       "      <td>Lipids</td>\n",
       "      <td>https://mad.ibcp.fr/molecule/Gb3?version=83899...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name Alias                 Category  \\\n",
       "0             tetrahydrocannabinol   THC           Small molecule   \n",
       "1       N-arachidonyl-ethanolamide   AEA           Small molecule   \n",
       "2              C60 fullerene model   F16  Synthetic nanoparticles   \n",
       "3             F216 fullerene model  F216  Synthetic nanoparticles   \n",
       "4             F576 fullerene model  F576  Synthetic nanoparticles   \n",
       "..                             ...   ...                      ...   \n",
       "398                   beta-Lactose   LAC                   Sugars   \n",
       "399                        Sucrose  SUCR                   Sugars   \n",
       "400                      Trehalose  TREH                   Sugars   \n",
       "401  Monosialodihexosylganglioside  DPG3                   Lipids   \n",
       "402          Globotriaosylceramide   Gb3                   Lipids   \n",
       "\n",
       "                                                  Lien  \n",
       "0    https://mad.ibcp.fr/molecule/THC?version=11124...  \n",
       "1    https://mad.ibcp.fr/molecule/AEA?version=11124...  \n",
       "2    https://mad.ibcp.fr/molecule/F16?version=66864...  \n",
       "3    https://mad.ibcp.fr/molecule/F216?version=6686...  \n",
       "4    https://mad.ibcp.fr/molecule/F576?version=6686...  \n",
       "..                                                 ...  \n",
       "398  https://mad.ibcp.fr/molecule/LAC?version=82073...  \n",
       "399  https://mad.ibcp.fr/molecule/SUCR?version=8207...  \n",
       "400  https://mad.ibcp.fr/molecule/TREH?version=8207...  \n",
       "401  https://mad.ibcp.fr/molecule/DPG3?version=8389...  \n",
       "402  https://mad.ibcp.fr/molecule/Gb3?version=83899...  \n",
       "\n",
       "[403 rows x 4 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lipid_data = parse_MAD_loop()\n",
    "lipid_data # en 1m30s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grodecoder-sandbox-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24620646de9e23ba93da68fffe9b3a585d6cb49ced5f4e226ee5fb49a47a6f45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
